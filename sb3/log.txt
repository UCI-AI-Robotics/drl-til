classstable_baselines3.ppo.PPO(
    policy, 
    env, 
    learning_rate=0.0003, 
    n_steps=2048, 
    batch_size=64, 
    n_epochs=10, 
    gamma=0.99, 
    gae_lambda=0.95, 
    clip_range=0.2, 
    clip_range_vf=None, 
    normalize_advantage=True, 
    ent_coef=0.0, 
    vf_coef=0.5, 
    max_grad_norm=0.5, 
    use_sde=False, 
    sde_sample_freq=-1, 
    rollout_buffer_class=None, 
    rollout_buffer_kwargs=None, 
    target_kl=None, 
    stats_window_size=100, 
    tensorboard_log=None, 
    policy_kwargs=None, 
    verbose=0, 
    seed=None, 
    device='auto', 
    _init_setup_model=True
)

# https://github.com/DLR-RM/rl-baselines3-zoo/blob/9a5b7aec3ba13b0f65fa3c78f3bf2093247507bc/hyperparams/sac.yml#L17
# SAC
Pendulum-v1:
  # callback:
  #   - rl_zoo3.callbacks.ParallelTrainCallback
  n_timesteps: 20000
  policy: 'MlpPolicy'
  learning_rate: !!float 1e-3

# https://github.com/DLR-RM/rl-baselines3-zoo/blob/9a5b7aec3ba13b0f65fa3c78f3bf2093247507bc/hyperparams/ppo.yml#L17
PPO
# Tuned
Pendulum-v1:
  n_envs: 4
  n_timesteps: !!float 1e5
  policy: 'MlpPolicy'
  n_steps: 1024
  gae_lambda: 0.95
  gamma: 0.9
  n_epochs: 10
  ent_coef: 0.0
  learning_rate: !!float 1e-3
  clip_range: 0.2
  use_sde: True
  sde_sample_freq: 4

100000